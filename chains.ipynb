{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNge0yW+x7gYeN5VnwX/Cc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noumantechie/langchain/blob/main/chains.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Retrieval base chain\n",
        "**bold text**"
      ],
      "metadata": {
        "id": "Es2y0TD06PIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain_community langchain_text_splitters langchain_google_genai langchain_huggingface faiss-cpu\n"
      ],
      "metadata": {
        "id": "N3vNyC4u74Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# Corrected FAISS import\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Import necessary chain functions\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "E20X9Sn26kES"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URL1 = \"https://techcrunch.com/2024/03/04/anthropic-claims-its-new-models-beat-gpt-4/\"\n",
        "URL2 = \"https://techcrunch.com/2024/03/28/ai21-labs-new-text-generating-ai-model-is-more-efficient-than-most/\""
      ],
      "metadata": {
        "id": "LnIF3HDh8l2i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader([URL1, URL2])\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "OSLg3Mqw8opg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=50,\n",
        ")\n",
        "chunks = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "kAWp5PbW8rfH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "bHqTcG_r9j10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = FAISS.from_documents(chunks , embeddings)\n",
        "retriever = vectorstore.as_retriever()\n"
      ],
      "metadata": {
        "id": "2R2IiXNk9kwt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "Answer the question \"{input}\" based solely on the context below:\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "If you can't find an answer, say \"I don't know.\"\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "OxR9dWHD-VrH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template(prompt_template)"
      ],
      "metadata": {
        "id": "f_m23PGb_HC-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    api_key=GOOGLE_API_KEY  # Corrected 'api_ket' to 'api_key'\n",
        ")"
      ],
      "metadata": {
        "id": "1D2cUf2F_REB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Create stuff chain**"
      ],
      "metadata": {
        "id": "zegz33MNB4jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combine_docs_chain = create_stuff_documents_chain(llm, prompt)"
      ],
      "metadata": {
        "id": "mM-r9R5l_Vzx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Retrieval chain**"
      ],
      "metadata": {
        "id": "V83-R4e4BvQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_retrieval_chain(retriever, combine_docs_chain)"
      ],
      "metadata": {
        "id": "Zm7kuYnp_bHR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain.invoke({\"input\": \"Liast the models and their token size of models only from Anthropic and Meta\"})\n"
      ],
      "metadata": {
        "id": "2sunAR4p_g9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBQTL3svA3gO",
        "outputId": "aaa4a263-acc4-4925-8d5f-980ccee4473c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'Liast the models and their token size of models only from Anthropic and Meta', 'context': [Document(id='e3fe54db-edcd-441d-960d-b297e63af18b', metadata={'source': 'https://techcrunch.com/2024/03/04/anthropic-claims-its-new-models-beat-gpt-4/', 'title': \"Anthropic claims its new AI chatbot models beat OpenAI's GPT-4 | TechCrunch\", 'description': 'Anthropic, the AI startup funded backed by Google, Amazon and others, has released its latest flagship GenAI models, Claude 3.', 'language': 'en-US'}, page_content='having models respond to questions and perform tasks using a simple set of guiding principles. For example, for Claude 3, Anthropic said that it added a principle — informed by crowdsourced feedback'), Document(id='5cbbaa8d-8b47-443c-a4f0-6f81e7087eee', metadata={'source': 'https://techcrunch.com/2024/03/28/ai21-labs-new-text-generating-ai-model-is-more-efficient-than-most/', 'title': \"AI21 Labs' new AI model can handle more context than most | TechCrunch\", 'description': 'Increasingly, the AI industry is moving toward generative AI models with longer contexts. But models with large context windows tend to be', 'language': 'en-US'}, page_content='“While there are a few initial academic examples of SSM models, this is the first commercial-grade, production-scale model,” Dagan said in an interview with TechCrunch. “This architecture, in'), Document(id='2dc834bd-15b6-44f9-aae2-e11a9d9913c3', metadata={'source': 'https://techcrunch.com/2024/03/04/anthropic-claims-its-new-models-beat-gpt-4/', 'title': \"Anthropic claims its new AI chatbot models beat OpenAI's GPT-4 | TechCrunch\", 'description': 'Anthropic, the AI startup funded backed by Google, Amazon and others, has released its latest flagship GenAI models, Claude 3.', 'language': 'en-US'}, page_content='Anthropic has disabled the models from identifying people — no doubt wary of the ethical and legal implications. And the company admits that Claude 3 is prone to making mistakes with “low-quality”'), Document(id='a6977aca-9f1e-4d13-b22f-65ef3d150a38', metadata={'source': 'https://techcrunch.com/2024/03/04/anthropic-claims-its-new-models-beat-gpt-4/', 'title': \"Anthropic claims its new AI chatbot models beat OpenAI's GPT-4 | TechCrunch\", 'description': 'Anthropic, the AI startup funded backed by Google, Amazon and others, has released its latest flagship GenAI models, Claude 3.', 'language': 'en-US'}, page_content='“We don’t believe that model intelligence is anywhere near its limits, and we plan to release [enhancements] to the Claude 3 model family over the next few months,” the company writes in a blog post.')], 'answer': \"I don't know.  The provided text mentions Anthropic's Claude 3, but doesn't give its token size or list any models from Meta.\"}\n"
          ]
        }
      ]
    }
  ]
}