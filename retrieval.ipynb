{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODqG10DKhAcG3tDmGvpoyV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noumantechie/langchain/blob/main/retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 1 Loading Document**"
      ],
      "metadata": {
        "id": "6xIId9kfXx5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU pypdf langchain-text-splitters langchain_huggingface \"langchain-chroma>=0.1.2\" langchain_google_genai langchain_core\n"
      ],
      "metadata": {
        "id": "UlB7HIQTxnEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "NTK4cPAD8oRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the PDF file\n",
        "pdf_path = \"/content/General_Instructions_candiadtes.pdf\"  # Ensure the correct file path\n",
        "loader = PyPDFLoader(pdf_path)"
      ],
      "metadata": {
        "id": "Ieh7CEWlNoef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now use load_and_split()\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "I1yFPZmdN4Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 Chunking**"
      ],
      "metadata": {
        "id": "0LYwrxZ2X4aW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=50,\n",
        ")\n",
        "chunks = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "DFA8e9hzYP0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 Generate Embeddings **"
      ],
      "metadata": {
        "id": "vbxjpBmVviMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an open-source Sentence Transformer model\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "fwwADWAowRt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4 Semantic Search and Storing into Database**"
      ],
      "metadata": {
        "id": "acYqy4Jb0qtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(documents=chunks , embedding=embeddings)"
      ],
      "metadata": {
        "id": "HYVzv_MQ2QvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "Mst4YGmd9-rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "vrFFk0L32gEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    api_key=GOOGLE_API_KEY  # Corrected 'api_ket' to 'api_key'\n",
        ")"
      ],
      "metadata": {
        "id": "BL3Csnuz27BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"SYSTEM: You are a question-answering bot.\n",
        "              Be factual in your responses.\n",
        "              Respond to the following question only using the context provided below:\n",
        "              Question: {question}\n",
        "              Context: {context}\n",
        "              If you don't know the answer, just say that you don't know.\n",
        "\n",
        "              \"\"\"\n",
        "\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n"
      ],
      "metadata": {
        "id": "_xKseUcu-bM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n"
      ],
      "metadata": {
        "id": "YQANlnGX_gkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"what is Testing & Interview Process ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1kD73UuA_zni",
        "outputId": "14c00719-9a2e-43a5-f7e1-173004c27926"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the provided text, the testing and interview process involves a test or screening test, followed by an interview for eligible candidates.  Eligible candidates will be contacted and must bring original documents to their interview.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}